server:
  port: 8090
management:
  endpoints:
    web:
      exposure:
        include: health, info, metrics
  endpoint:
    health:
      show-details: always

spring:
  application:
    name: import-service-point
  servlet:
    multipart:
      max-file-size: 300MB
      max-request-size: 300MB
  datasource:
    url: jdbc:postgresql://localhost:5440/import-service
    username: user
    password: pwd
    driver-class-name: org.postgresql.Driver
    application:
      name: import-service-point
  batch:
    jdbc:
      initialize-schema: NEVER
      isolation-level-for-create: default
    job:
      enabled: false
  jpa:
    open-in-view: false
  security:
    oauth2:
      resourceserver:
        jwt:
          issuer-uri: https://login.microsoftonline.com/2cda5d11-f0ac-46b3-967d-af1b2e1bd01a/v2.0
      client:
        provider:
          azure:
            issuer-uri: https://login.microsoftonline.com/2cda5d11-f0ac-46b3-967d-af1b2e1bd01a/v2.0
        registration:
          azure:
            authorization-grant-type: client_credentials
            client-id: ${SCHEDULING_CLIENT_ID}
            client-secret: ${SCHEDULING_CLIENT_SECRET}
            scope:
              - api://87e6e634-6ba1-4e7a-869d-3348b4c3eafc/.default
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      auto-offset-reset: earliest
      enable-auto-commit: true
      properties:
        spring:
          json:
            trusted:
              packages: "*"
        max:
          poll:
            interval:
              ms: 1200000
    producer:
      properties:
        max:
          request:
            size: 3000000
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      retries: 1


kafka:
  atlas:
    user:
      administration:
        topic: atlas.user.administration
        groupId: atlas.kafka.lidi.user.administration.groupId
    mail:
      topic: atlas.mail
      groupId: atlas.kafka.mail.groupId
auth:
  audience:
    service-name: 87e6e634-6ba1-4e7a-869d-3348b4c3eafc

atlas:
  client:
    gateway:
      url: "http://localhost:8888"

mail:
  receiver:
    import-service-point: TechSupport-ATLAS@sbb.ch

batch:
  config:
    service-point-directory:
      chuck-size: 20

amazon:
  region: "eu-central-1"
  bucketConfigs:
    export-files:
      accessKey: ${AMAZON_S3_ACCESS_KEY}
      secretKey: ${AMAZON_S3_SECRET_KEY}
      bucketName: "atlas-data-export-dev-dev"
      objectExpirationDays: 30
    hearing-documents:
      accessKey: ${AMAZON_S3_HEARING_DOCS_ACCESS_KEY}
      secretKey: ${AMAZON_S3_HEARING_DOCS_SECRET_KEY}
      bucketName: "atlas-hearing-documents-dev-dev"
      objectExpirationDays: 100000
